# -*- coding: utf-8 -*-
"""PROJECTJOVAC.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1XatA72s2ls-i9uYuZvMV_J6U_Bcjzx5l
"""

import pandas as pd
from sklearn.datasets import load_digits
df= load_digits()
print(df)

"""APPLY **PREPROCESSING StandardScalere**


"""

import pandas as pd
dic=pd.DataFrame(df['data'],columns=df['feature_names'])
X=dic
y=df['target']

from sklearn.preprocessing import StandardScaler 
model1=StandardScaler()
X_scaled=model1.fit_transform(X)
print(X_scaled)

""" **APPLY PCA**

"""

from sklearn.decomposition import PCA
pca=PCA(0.67)
X_pca=pca.fit_transform(X)
print("post pca shape",X_pca.shape)
print("pre pca shape",X.shape)

pca.explained_variance_ratio_

pca.n_components_

from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=8)
logistic=LogisticRegression()
logistic.fit(X_train,y_train)
print(logistic.score(X_test,y_test))

X_train_pca,X_test_pca,y_train_pca,y_test_pca=train_test_split(X_pca,y,test_size=0.2,random_state=9)
logistic1=LogisticRegression()
logistic1.fit(X_train_pca,y_train_pca)
print(logistic1.score(X_test_pca,y_test_pca))

pca1=PCA(n_components=3)
X_pca1=pca1.fit_transform(X)
print(X_pca1.shape)

print(X_pca1)

print(pca1.explained_variance_ratio_)

X_train_pca1,X_test_pca1,y_train_pca1,y_test_pca1=train_test_split(X_pca1,y,test_size=0.2,random_state=8)
logistic2=LogisticRegression()
logistic2.fit(X_train_pca1,y_train_pca1)
print(logistic2.score(X_test_pca1,y_test_pca1))

"""**APPLY** (a) LogisticRegression
    (b) SVM
    (c) KNN
    (d) DecisionTree
    (e) RandomForest**

(a) LogisticRegression
"""

X=df['data']
y=df['target']
print(X)
print('-----------------------------')
print(y)

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.8,random_state=9)

from sklearn.linear_model import LogisticRegression 
model1=LogisticRegression()
model1.fit(X,y)
a=model1.predict(X_test)
print(a)

"""(b) SVM"""

from sklearn.svm import SVC
model2=SVC(kernel='poly')
model2.fit(X_train,y_train)

b=model2.predict(X_test)
print(b)

"""c) KNN"""

from sklearn.neighbors import KNeighborsClassifier
model3=KNeighborsClassifier(n_neighbors=3)
model3.fit(X_train,y_train)

c=model3.predict(X_test)
print(c)

"""(d) DecisionTree"""

from sklearn.tree import DecisionTreeClassifier
model4=DecisionTreeClassifier()
model4.fit(X_train,y_train)

d=model4.predict(X_test)
print(d)

"""(e) RandomForest"""

from sklearn.ensemble import RandomForestClassifier 
model5=RandomForestClassifier()  
model5.fit(X_train,y_train)
e=model5.predict(X_test)
print(e)

"""Find accuracy of all above algorithm and finds which provides best accuracy"""

print("Logistic regression accuracy",model1.score(X_test,y_test))
print("SVM Accuracy",model2.score(X_test,y_test))
print("KNN Accuracy",model3.score(X_test,y_test))
print("DecisionTree Accuracy",model4.score(X_test,y_test))
print("RandomTree Accuracy",model5.score(X_test,y_test))

"""LOGISTIC REGRESSION HAS THE HIGHEST ACCURACY

Find confusion matrix of all above algorithms and show it by heatmap of seaborn library.

(a) LogisticRegression
"""

from sklearn.metrics import confusion_matrix
cm1=confusion_matrix(y_test,a)
print(cm1)

import matplotlib.pyplot as plt
plt.figure(figsize=(10,7))
import seaborn as sns
sns.heatmap(cm1,annot=True)
plt.xlabel('Predicted')
plt.ylabel('Truth')
plt.show()

"""(b) SVM"""

cm2=confusion_matrix(y_test,b)
print(cm2)

sns.heatmap(cm2,annot=True)
plt.xlabel('Predicted')
plt.ylabel('Truth')
plt.show()

"""(c)KNN"""

cm3=confusion_matrix(y_test,c)
print(cm3)

sns.heatmap(cm3,annot=True)
plt.xlabel('Predicted')
plt.ylabel('Truth')
plt.show()

"""(d) DecisionTree"""

cm4=confusion_matrix(y_test,d)
print(cm4)

sns.heatmap(cm4,annot=True)
plt.xlabel('Predicted')
plt.ylabel('Truth')
plt.show()

"""(e) RandomForest"""

cm5=confusion_matrix(y_test,e)
print(cm5)

sns.heatmap(cm5,annot=True)
plt.xlabel('Predicted')
plt.ylabel('Truth')
plt.show()