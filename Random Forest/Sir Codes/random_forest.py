# -*- coding: utf-8 -*-
"""Random Forest.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1V-EXGT3U8eY78SgCEwlmo33UBRGRavxP
"""

from sklearn.datasets import load_digits
d=load_digits()
d

print(list(d.keys()))

import pandas as pd
df=pd.DataFrame(d['data'],columns=d['feature_names'])
df

df['target']=d['target']
print(len(df['target']))

df

X=df.drop('target',axis='columns')
y=df['target']
from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2)
print(len(X_train))
print(len(X_test))

from sklearn.ensemble import RandomForestClassifier 
from sklearn.tree import DecisionTreeClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
model=RandomForestClassifier()                 
model1=DecisionTreeClassifier()                                  #model=RandomForestClassifier(n_estimators=10)
model2=LogisticRegression()
model3=SVC()
model4=KNeighborsClassifier()
model.fit(X_train,y_train)
model1.fit(X_train,y_train)
model2.fit(X_train,y_train)
model3.fit(X_train,y_train)
model4.fit(X_train,y_train)
y_pred=model.predict(X_test)
print(y_pred)

print("Random Forest Accuracy",model.score(X_test,y_test))
print("Decision Tree Accuracy",model1.score(X_test,y_test))
print("Logistic Regression Accuracy",model2.score(X_test,y_test))
print("SVM Accuracy",model3.score(X_test,y_test))
print("KNN Accuracy",model4.score(X_test,y_test))

from sklearn.metrics import classification_report,confusion_matrix,accuracy_score
cm=confusion_matrix(y_test,y_pred)
print(cm)

import matplotlib.pyplot as plt
plt.figure(figsize=(10,7))
import seaborn as sns
sns.heatmap(cm,annot=True)
plt.xlabel('Predicted')
plt.ylabel('Truth')
plt.show()

print(classification_report(y_test,y_pred))

print(accuracy_score(y_test,y_pred))